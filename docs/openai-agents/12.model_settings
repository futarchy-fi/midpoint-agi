Model settings

ModelSettings dataclass

Settings to use when calling an LLM.

This class holds optional model configuration parameters (e.g. temperature, top_p, penalties, truncation, etc.).

Not all models/providers support all of these parameters, so please check the API documentation for the specific model and provider you are using.

Source code in src/agents/model_settings.py
temperature class-attribute instance-attribute


temperature: float | None = None
The temperature to use when calling the model.

top_p class-attribute instance-attribute


top_p: float | None = None
The top_p to use when calling the model.

frequency_penalty class-attribute instance-attribute


frequency_penalty: float | None = None
The frequency penalty to use when calling the model.

presence_penalty class-attribute instance-attribute


presence_penalty: float | None = None
The presence penalty to use when calling the model.

tool_choice class-attribute instance-attribute


tool_choice: (
    Literal["auto", "required", "none"] | str | None
) = None
The tool choice to use when calling the model.

parallel_tool_calls class-attribute instance-attribute


parallel_tool_calls: bool | None = False
Whether to use parallel tool calls when calling the model.

truncation class-attribute instance-attribute


truncation: Literal['auto', 'disabled'] | None = None
The truncation strategy to use when calling the model.

max_tokens class-attribute instance-attribute


max_tokens: int | None = None
The maximum number of output tokens to generate.

resolve


resolve(override: ModelSettings | None) -> ModelSettings
Produce a new ModelSettings by overlaying any non-None values from the override on top of this instance.

Source code in src/agents/model_settings.py