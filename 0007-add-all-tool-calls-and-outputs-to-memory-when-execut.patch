From a5db3f309a14ad7cf4bd70681b612f73f7b0c84a Mon Sep 17 00:00:00 2001
From: krandder <azsantos.k@gmail.com>
Date: Mon, 14 Apr 2025 19:11:17 -0700
Subject: [PATCH 7/7] add all tool calls and outputs to memory, when executing
 task

---
 src/midpoint/agents/task_executor.py | 207 ++++++++++++++-------------
 1 file changed, 110 insertions(+), 97 deletions(-)

diff --git a/src/midpoint/agents/task_executor.py b/src/midpoint/agents/task_executor.py
index 4090230..5e776dd 100644
--- a/src/midpoint/agents/task_executor.py
+++ b/src/midpoint/agents/task_executor.py
@@ -148,7 +148,7 @@ class TaskExecutor:
 
     def _save_interaction_to_memory(self, context: TaskContext):
         """
-        Save the conversation to memory, following the GoalDecomposer's pattern.
+        Save the conversation buffer to memory.
         """
         if not context.state.memory_repository_path or not context.state.memory_hash:
             logger.info("No memory repo or hash available, skipping _save_interaction_to_memory")
@@ -162,19 +162,53 @@ class TaskExecutor:
             # Create timestamped filename
             timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
             
-            # Format conversation content
+            # Format conversation content from the buffer
             content = f"# Task Execution Conversation\n\nTimestamp: {timestamp}\n\n"
             
-            # Add each relevant entry from the conversation buffer
+            # Add each entry from the conversation buffer based on role
             for entry in self.conversation_buffer:
-                entry_type = entry.get("type", "unknown")
-                
-                # Format based on entry type
-                if entry_type == "user_message":
-                    content += f"## User Message\n\n{entry.get('user_prompt', '')}\n\n"
-                elif entry_type == "assistant_response":
-                    content += f"## Assistant Response\n\n{entry.get('final_content', '')}\n\n"
-            
+                role = entry.get("role", "unknown")
+                entry_content = entry.get("content", "") # Default to empty string if content is None or missing
+                if entry_content is None: # Ensure entry_content is never None for formatting
+                    entry_content = "" 
+
+                if role == "user":
+                    content += f"## User Message\n\n{entry_content}\n\n"
+                elif role == "assistant":
+                    # Check for tool calls within the assistant message
+                    tool_calls = entry.get("tool_calls")
+                    if tool_calls and isinstance(tool_calls, list):
+                         content += f"## Assistant Action (Tool Call)\n\n"
+                         if entry_content: # Include any text assistant said before the call
+                              content += f"{entry_content}\n\n" 
+                         for i, tc in enumerate(tool_calls):
+                              func = tc.get("function", {})
+                              tool_name = func.get("name", "unknown_tool")
+                              tool_args = func.get("arguments", "{}")
+                              content += f"**Tool Call {i+1}:** `{tool_name}`\n"
+                              # Format arguments nicely, maybe as a code block
+                              try:
+                                   # Attempt to parse and pretty-print JSON arguments
+                                   parsed_args = json.loads(tool_args)
+                                   formatted_args = json.dumps(parsed_args, indent=2)
+                                   content += f"```json\n{formatted_args}\n```\n"
+                              except json.JSONDecodeError:
+                                   # Fallback for non-JSON or malformed arguments
+                                   content += f"```\n{tool_args}\n```\n"
+                         content += "\n" # Add newline after tool calls section
+                    else:
+                         # Regular assistant text response
+                         content += f"## Assistant Response\n\n{entry_content}\n\n"
+                elif role == "tool":
+                    tool_name = entry.get("name", "unknown_tool")
+                    tool_call_id = entry.get("tool_call_id", "unknown_id")
+                    content += f"## Tool Result (`{tool_name}`, ID: {tool_call_id})\n\n"
+                    content += f"```\n{entry_content}\n```\n\n" # Put tool result in code block
+                elif role == "system" and "[Error serializing message:" in entry_content:
+                     # Handle the placeholder error message we added earlier
+                     content += f"## System Error\n\n{entry_content}\n\n"
+                # Note: We generally skip system messages unless it's our error placeholder
+
             # Add metadata
             content += "## Metadata\n\n"
             content += f"- Task ID: {context.metadata.get('task_id', 'unknown')}\n"
@@ -529,111 +563,90 @@ Memory Hash: {context.state.memory_hash}"""
         # Add the user prompt as the final message
         messages.append({"role": "user", "content": user_prompt})
         
-        # Record user prompt in conversation buffer
-        self.conversation_buffer.append({
-            "type": "user_message",
-            "user_prompt": user_prompt,
-            "timestamp": datetime.datetime.now().isoformat()
-        })
-        
         # Track tool usage for metadata
         tool_usage = []
         
         try:
             # Get the task execution plan from the model
-            message, tool_calls = self.tool_processor.run_llm_with_tools(
+            final_messages, tool_calls = self.tool_processor.run_llm_with_tools(
                 messages,
                 model="gpt-4o-mini",
                 validate_json_format=True,
                 max_tokens=3000
             )
             
-            # Process tool calls and update tool usage
+            # === POPULATE conversation_buffer FROM final_messages ===
+            # Ensure final_messages is a list
+            if not isinstance(final_messages, list):
+                logger.error(f"ToolProcessor did not return a list of messages: {type(final_messages)}")
+                # Handle error case appropriately, maybe raise or return default error
+                final_messages = [] # Default to empty list to prevent downstream errors
+
+            # Clear and repopulate buffer from the actual final conversation history
+            self.conversation_buffer = []
+            # Skip initial system message(s) when adding to buffer for saving
+            system_message_count = sum(1 for msg in messages if msg.get('role') == 'system')
+            relevant_messages = final_messages[system_message_count:] # Get messages after system prompts
+            
+            # Convert message objects/dicts to a serializable format for the buffer
+            for msg in relevant_messages:
+                if isinstance(msg, dict):
+                    # Already a dictionary, ensure content is present
+                    if 'content' not in msg:
+                         msg['content'] = None # Ensure content key exists, even if null
+                    self.conversation_buffer.append(msg)
+                else:
+                    # Attempt to convert potential message objects (like from OpenAI response)
+                    try:
+                        msg_dict = {
+                            "role": getattr(msg, 'role', 'unknown'),
+                            "content": getattr(msg, 'content', None),
+                        }
+                        # Handle tool calls if present on the object
+                        if hasattr(msg, 'tool_calls') and msg.tool_calls:
+                            msg_dict['tool_calls'] = [
+                                {
+                                    "id": tc.id,
+                                    "type": tc.type,
+                                    "function": {
+                                        "name": tc.function.name,
+                                        "arguments": tc.function.arguments
+                                    }
+                                } for tc in msg.tool_calls
+                            ]
+                        # Handle tool call ID if present (for tool role messages)
+                        if hasattr(msg, 'tool_call_id'):
+                             msg_dict['tool_call_id'] = msg.tool_call_id
+                        # Handle tool name if present (for tool role messages)
+                        if hasattr(msg, 'name'):
+                             msg_dict['name'] = msg.name
+                             
+                        self.conversation_buffer.append(msg_dict)
+                    except Exception as e:
+                        logger.error(f"Could not serialize message object for buffer: {e} - {msg}")
+                        # Append a placeholder if serialization fails
+                        self.conversation_buffer.append({"role": "system", "content": f"[Error serializing message: {e}]"})
+
+            # Process tool calls and update tool usage (for ExecutionResult metadata)
             if tool_calls:
                 logger.debug(f"Processing tool_calls: {tool_calls}") # DEBUG: Log the raw tool_calls list
                 for tool_call in tool_calls:
-                    logger.debug(f"  Processing individual tool_call: {tool_call}") # DEBUG: Log individual call
-                    logger.debug(f"  Type of tool_call: {type(tool_call)}") # DEBUG: Log type
-                    tool_usage.append(tool_call)
-
-                    # Record tool usage in conversation buffer
-                    # --- START EDIT ---
-                    # Correctly extract tool name and arguments, handling object/dict variations
-                    tool_name = 'unknown_tool' # Initialize
-                    tool_args_str = '{}' # Default to empty JSON string
-                    tool_args_parsed = {}
-                    logger.debug(f"  Initial tool_name: {tool_name}") # DEBUG
-                    try:
-                        # --- Check 1: Attribute access ---
-                        has_function_attr = hasattr(tool_call, 'function') and tool_call.function is not None
-                        logger.debug(f"  Checking hasattr(tool_call, 'function'): {has_function_attr}") # DEBUG
-                        if has_function_attr:
-                            tool_name = tool_call.function.name
-                            tool_args_str = tool_call.function.arguments # Arguments are typically JSON strings
-                            logger.debug(f"    Extracted via attributes: name={tool_name}, args_str={tool_args_str}") # DEBUG
-                        
-                        # --- Check 2: Dictionary access (if attribute access failed) ---
-                        elif isinstance(tool_call, dict):
-                            logger.debug(f"  Checking isinstance(tool_call, dict): True") # DEBUG
-                            # --- START REVISED DICT LOGIC ---
-                            # Directly access 'tool'/'name' and 'args'/'arguments' keys
-                            tool_name = tool_call.get('tool', tool_call.get('name', 'unknown_tool_dict_fallback')) # Check 'tool' first, then 'name'
-                            raw_args = tool_call.get('args', tool_call.get('arguments', {})) # Check 'args' first, then 'arguments'
-                            logger.debug(f"    Got raw_args: {raw_args}, type: {type(raw_args)}") # DEBUG
-                            
-                            # Arguments might be a string (JSON) or already a dict
-                            if isinstance(raw_args, str):
-                                tool_args_str = raw_args
-                            elif isinstance(raw_args, dict):
-                                tool_args_str = json.dumps(raw_args) # Convert dict back to JSON string for consistent parsing below
-                                logger.debug(f"    Converted dict args back to string: {tool_args_str}")
-                            else:
-                                logger.warning(f"    Unexpected type for args: {type(raw_args)}. Defaulting to empty dict.")
-                                tool_args_str = '{}' # Default if unexpected type
-                            # --- END REVISED DICT LOGIC ---
-                            logger.debug(f"    Extracted via dict: name={tool_name}, args_str={tool_args_str}") # DEBUG
-                        else:
-                            logger.warning(f"  Tool call is neither object with function nor dict: {tool_call}") # DEBUG
-
-                        # --- Argument Parsing ---
-                        logger.debug(f"  Attempting to parse args_str: {tool_args_str}") # DEBUG
-                        tool_args_parsed = json.loads(tool_args_str)
-                        logger.debug(f"    Successfully parsed args: {tool_args_parsed}") # DEBUG
-
-                    except Exception as e:
-                        # Log potential issues with accessing/parsing, but proceed
-                        logger.warning(f"Could not fully parse tool call info: {tool_call}. Error: {e}", exc_info=True) # Add traceback
-                        tool_args_parsed = {} # Use empty dict if parsing fails
-                        # Keep tool_name as it was potentially set before the error
-
-                    logger.debug(f"  Final tool_name before append: {tool_name}") # DEBUG
-                    logger.debug(f"  Final tool_args_parsed before append: {tool_args_parsed}") # DEBUG
-                    self.conversation_buffer.append({
-                        "type": "tool_usage",
-                        "tool_name": tool_name,
-                        "tool_args": tool_args_parsed, # Store parsed args if possible
-                        "timestamp": datetime.datetime.now().isoformat()
-                    })
-                    # --- END EDIT ---
+                    tool_usage.append(tool_call) # Keep populating tool_usage for metadata
+            
+            # Get the final assistant message content (for parsing the final JSON response)
+            # Find the *last* message from the assistant in the actual final_messages list
+            final_assistant_message = next((msg for msg in reversed(final_messages) if isinstance(msg, dict) and msg.get("role") == "assistant"), None)
             
-            # Get the final assistant message content
-            if isinstance(message, list):
-                # If message is a list, get the last message's content
-                final_content = message[-1].get('content', '')
+            if final_assistant_message:
+                final_content = final_assistant_message.get('content', '')
             else:
-                # If message is a dict or object, get its content
-                final_content = message.get('content') if isinstance(message, dict) else message.content
+                 # Handle case where no final assistant message content is found
+                 logger.warning("No final assistant message content found in the conversation history.")
+                 final_content = "{}" # Default to empty JSON to avoid errors
 
             # Log the final raw response for debugging
-            logger.debug(f"Final Raw model response: {final_content}")
+            logger.debug(f"Final Raw model response (for JSON parsing): {final_content}")
                 
-            # Record final assistant response in conversation buffer
-            self.conversation_buffer.append({
-                "type": "assistant_response",
-                "final_content": final_content,
-                "timestamp": datetime.datetime.now().isoformat()
-            })
-            
             # --- Aligned Error Handling --- 
             output_data = None
             try:
-- 
2.39.5 (Apple Git-154)

